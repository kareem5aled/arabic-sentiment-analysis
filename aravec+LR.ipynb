{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "aravec+LR",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6D0SZQQUaUM"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "df_main = pd.read_csv(\"full_labeled_data.csv\", names = [\"Tweet\", \"Sentiment\"])\r\n",
        "df_main = df_main.sample(frac=1)\r\n",
        "\r\n",
        "\r\n",
        "x_train = df_main[\"Tweet\"][:50000].to_numpy()\r\n",
        "y_train = df_main[\"Sentiment\"][:50000].to_numpy()\r\n",
        "\r\n",
        "x_test = df_main[\"Tweet\"][50000:].to_numpy()\r\n",
        "y_test = df_main[\"Sentiment\"][50000:].to_numpy()\r\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDXZtpOwj5xR",
        "outputId": "66f346a2-178e-4556-a805-a82f397f095f"
      },
      "source": [
        "!pip install gensim spacy nltk\r\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.1.2)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy) (53.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha5OeXX0kXmX"
      },
      "source": [
        "import gensim\r\n",
        "import re\r\n",
        "import spacy\r\n",
        "\r\n",
        "# Clean/Normalize Arabic Text\r\n",
        "def clean_str(text):\r\n",
        "    search = [\"أ\",\"إ\",\"آ\",\"ة\",\"_\",\"-\",\"/\",\".\",\"،\",\" و \",\" يا \",'\"',\"ـ\",\"'\",\"ى\",\"\\\\\",'\\n', '\\t','&quot;','?','؟','!']\r\n",
        "    replace = [\"ا\",\"ا\",\"ا\",\"ه\",\" \",\" \",\"\",\"\",\"\",\" و\",\" يا\",\"\",\"\",\"\",\"ي\",\"\",' ', ' ',' ',' ? ',' ؟ ',' ! ']\r\n",
        "    \r\n",
        "    #remove tashkeel\r\n",
        "    p_tashkeel = re.compile(r'[\\u0617-\\u061A\\u064B-\\u0652]')\r\n",
        "    text = re.sub(p_tashkeel,\"\", text)\r\n",
        "    \r\n",
        "    #remove longation\r\n",
        "    p_longation = re.compile(r'(.)\\1+')\r\n",
        "    subst = r\"\\1\\1\"\r\n",
        "    text = re.sub(p_longation, subst, text)\r\n",
        "    \r\n",
        "    text = text.replace('وو', 'و')\r\n",
        "    text = text.replace('يي', 'ي')\r\n",
        "    text = text.replace('اا', 'ا')\r\n",
        "    \r\n",
        "    for i in range(0, len(search)):\r\n",
        "        text = text.replace(search[i], replace[i])\r\n",
        "    \r\n",
        "    #trim    \r\n",
        "    text = text.strip()\r\n",
        "\r\n",
        "    return text\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-VbfcAykbHv",
        "outputId": "21a063c5-1ed9-4f6a-fb5a-b0acbec5895e"
      },
      "source": [
        "!wget \"https://bakrianoo.s3-us-west-2.amazonaws.com/aravec/full_uni_cbow_300_twitter.zip\"\r\n",
        "!unzip \"full_uni_cbow_300_twitter.zip\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-22 01:21:16--  https://bakrianoo.s3-us-west-2.amazonaws.com/aravec/full_uni_cbow_300_twitter.zip\n",
            "Resolving bakrianoo.s3-us-west-2.amazonaws.com (bakrianoo.s3-us-west-2.amazonaws.com)... 52.218.178.81\n",
            "Connecting to bakrianoo.s3-us-west-2.amazonaws.com (bakrianoo.s3-us-west-2.amazonaws.com)|52.218.178.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2833686412 (2.6G) [application/zip]\n",
            "Saving to: ‘full_uni_cbow_300_twitter.zip’\n",
            "\n",
            "full_uni_cbow_300_t 100%[===================>]   2.64G  30.9MB/s    in 78s     \n",
            "\n",
            "2021-02-22 01:22:35 (34.4 MB/s) - ‘full_uni_cbow_300_twitter.zip’ saved [2833686412/2833686412]\n",
            "\n",
            "Archive:  full_uni_cbow_300_twitter.zip\n",
            "  inflating: full_uni_cbow_300_twitter.mdl  \n",
            "  inflating: full_uni_cbow_300_twitter.mdl.trainables.syn1neg.npy  \n",
            "  inflating: full_uni_cbow_300_twitter.mdl.wv.vectors.npy  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebzBh4iDkdid",
        "outputId": "0dbacd8c-9c3e-4c0e-e29d-685fb21be1e9"
      },
      "source": [
        "model = gensim.models.Word2Vec.load(\"full_uni_cbow_300_twitter.mdl\")\r\n",
        "print(\"We've\",len(model.wv.index2word),\"vocabularies\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We've 1259756 vocabularies\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ85PM84lbAv"
      },
      "source": [
        "%mkdir spacyModel\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGzlwE_xlcvc"
      },
      "source": [
        "model.wv.save_word2vec_format(\"./spacyModel/aravec.txt\")\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8d_ZASevlfhs"
      },
      "source": [
        "!gzip ./spacyModel/aravec.txt\r\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGSk_uxApQFC",
        "outputId": "9230f6dc-5f1b-4318-c0b2-53c3e134e788"
      },
      "source": [
        "!python -m spacy  init-model ar spacy.aravec.model --vectors-loc ./spacyModel/aravec.txt.gz"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r⠙ Creating model...\r\u001b[2K\u001b[38;5;2m✔ Successfully created model\u001b[0m\n",
            "⠙ Reading vectors from spacyModel/aravec.txt.gztcmalloc: large alloc 1511710720 bytes == 0x4098000 @  0x7f60e40e8001 0x7f60e1c664ff 0x7f60e1cb6b08 0x7f60e1cbaac7 0x7f60e1d591a3 0x50a4a5 0x50cc96 0x5095c8 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x588d41 0x59fd0e 0x50d256 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x509900 0x50a2fd 0x50beb4 0x507be4 0x5161c5 0x50a12f 0x50beb4 0x507be4\n",
            "1259756it [01:59, 10583.89it/s]\n",
            "\u001b[2K\u001b[38;5;2m✔ Loaded vectors from spacyModel/aravec.txt.gz\u001b[0m\n",
            "\u001b[38;5;2m✔ Sucessfully compiled vocab\u001b[0m\n",
            "1259946 entries, 1259756 vectors\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8Xo3royp9VU"
      },
      "source": [
        "nlp = spacy.load(\"./spacy.aravec.model/\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2m7RMbVqfoA"
      },
      "source": [
        "class Preprocessor:\r\n",
        "    def __init__(self, tokenizer, **cfg):\r\n",
        "        self.tokenizer = tokenizer\r\n",
        "\r\n",
        "    def __call__(self, text):\r\n",
        "        preprocessed = clean_str(text)\r\n",
        "        return self.tokenizer(preprocessed)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ScJ4e2wqg2J"
      },
      "source": [
        "nlp.tokenizer = Preprocessor(nlp.tokenizer)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbmJJgdCrQF0"
      },
      "source": [
        "x_train2=[0]*50000\r\n",
        "y_train2=[0]*len(y_train)\r\n",
        "\r\n",
        "i=0\r\n",
        "for i in range(len(y_train)):\r\n",
        "  if y_train[i] == 'Positive':\r\n",
        "\r\n",
        "    y_train2[i]=1\r\n",
        "\r\n",
        "  elif y_train[i] == 'Negative':\r\n",
        "\r\n",
        "    y_train2[i]=-1\r\n",
        "\r\n",
        "  else:\r\n",
        "    y_train2[i]=0\r\n",
        "\r\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o16o1dbw7XS"
      },
      "source": [
        "train_arrays=[0]*len(x_train)\r\n",
        "for i in range(len(x_train)):\r\n",
        "  train_arrays[i]=nlp(x_train[i]).vector"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ9dd3aFNLI7"
      },
      "source": [
        "test_arrays=[0]*len(x_test)\r\n",
        "for i in range(len(x_test)):\r\n",
        "  test_arrays[i]=nlp(x_test[i]).vector\r\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2m2aM7V05mq",
        "outputId": "af884496-1adb-4ae8-844d-892e5e498c00"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\r\n",
        "\r\n",
        "\r\n",
        "classifier =  LogisticRegression(multi_class='multinomial',max_iter=1000, solver='lbfgs')\r\n",
        "classifier.fit(train_arrays, y_train2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
              "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTyn3D8y28FR"
      },
      "source": [
        "x_test2=[0]*5002  \r\n",
        "y_test2=[0]*5002\r\n",
        "\r\n",
        "i=0\r\n",
        "for i in range(len(x_test)):\r\n",
        "  if y_test[i] == 'Positive':\r\n",
        "    x_test2[i] = nlp(x_test[i]).vector\r\n",
        "    y_test2[i]=1\r\n",
        "\r\n",
        "  elif y_test[i] == 'Negative':\r\n",
        "    x_test2[i] = nlp(x_test[i]).vector\r\n",
        "\r\n",
        "    y_test2[i]=-1\r\n",
        "\r\n",
        "  else:\r\n",
        "    x_test2[i] = nlp(x_test[i]).vector\r\n",
        "    y_test2[i]=0"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh41mlLo29Z3"
      },
      "source": [
        "prediction = classifier.predict(x_test2)\r\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZgOV6g8B6VaQ",
        "outputId": "9c695989-09d8-4c5d-ce79-889cb7145367"
      },
      "source": [
        "import sklearn\r\n",
        "sklearn.metrics.recall_score(y_test2, prediction, average = None)\r\n",
        "sklearn.metrics.f1_score(y_test2, prediction, average = None)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.46577017, 0.91610443, 0.60258065])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}