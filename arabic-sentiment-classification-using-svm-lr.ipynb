{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Sentiment Analysis in Arabic tweets using sklearn ML algorithms and 1,2,3 gram features"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\n\nimport sklearn \nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nimport random\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint('\\n'.join(os.listdir(\"../input\")))\n\n# Any results you write to the current directory are saved as output.","execution_count":7,"outputs":[{"output_type":"stream","text":"kaust-arabic-nlp\narabicnlp\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# define functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef load2(file):\n#     pos_training = '../input/train_Arabic_tweets_positive_20190413.tsv'\n#     neg_training = '../input/train_Arabic_tweets_negative_20190413.tsv'\n    \n#     pos_train_data, pos_train_labels = read_tsv(pos_train_file)\n#     neg_train_data, neg_train_labels = read_tsv(neg_train_file)\n\n    df_main = pd.read_csv(file)\n    df_main = df_main.sample(frac=1)\n    df_main['sentiment'] = df_main['sentiment'].str.lower()\n    df_main = df_main.replace(['positive', 'negative', 'neutral'], [0, 1, 2])\n    \n    \n    df_test = df_main[50000:]\n    df_train = df_main[:50000]\n\n    x_train = df_train['text'].tolist()\n    y_train = df_train['sentiment'].tolist()\n\n    x_test = df_test['text'].tolist()\n    y_test = df_test['sentiment'].tolist()\n    \n   \n    \n    print(\"data sample\")\n#     print(df_main.head())\n#     print('train data: # of pos:{}\\t# of neg:{}\\t'.format(y_train.count('pos'), y_train.count('neg')))\n#     print('test data: # of pos:{}\\t# of neg:{}\\t'.format(y_test.count('pos'), y_test.count('neg')))\n#     print('number of classese = ' + str())\n    print('------------------------------------')\n    return x_train, y_train, x_test, y_test\n\n####################################################\n\ndef do_sa(n, my_classifier, name, my_data):\n    x_train, y_train, x_test, y_test = my_data\n    print('parameters')\n    print('n grams:', n)\n    print('classifier:', my_classifier.__class__.__name__)\n    print('------------------------------------')\n\n    pipeline = Pipeline([\n        ('vect', CountVectorizer()),\n        ('clf', my_classifier),\n    ])\n\n# TfidfVectorizer(min_df=0.0001, max_df=0.95,\n#                                  analyzer='word', lowercase=True,\n#                                  ngram_range=(1, n))),\n    pipeline.fit(x_train, y_train)\n    feature_names = pipeline.named_steps['vect'].get_feature_names()\n\n    y_predicted = pipeline.predict(x_test)\n\n    # Print the classification report\n    print(metrics.classification_report(y_test, y_predicted,\n                                        target_names=['pos', 'neg', 'neut']))\n\n    # Print the confusion matrix\n    cm = metrics.confusion_matrix(y_test, y_predicted)\n    print(cm)\n    print('# of features:', len(feature_names))\n    print('sample of features:', random.sample(feature_names, 40))\n    f1 = f1_score(y_test, y_predicted, average = None)\n    accuracy = accuracy_score(y_test, y_predicted)\n    precision = (precision_score(y_test, y_predicted, average=\"weighted\"))\n    recall =  (recall_score(y_test, y_predicted, average=None))\n    return name, n, accuracy, precision, recall, (f1[0] + f1[1])/2\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = load2(\"../input/kaust-arabic-nlp/full_labeled_data.csv\")\n# dataset[0]","execution_count":5,"outputs":[{"output_type":"stream","text":"data sample\n------------------------------------\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = dataset[1]\nprint(\"TRAIN DATASET\")\nprint(\"Positve, negative , neutral count = \")\nprint(labels.count(0), labels.count(1), labels.count(2))\nprint('-------------------------------------')\nlabels = dataset[3]\nprint(\"TEST DATASSET\")\nprint(\"Positve, negative , neutral count = \")\nprint(labels.count(0), labels.count(1), labels.count(2))","execution_count":6,"outputs":[{"output_type":"stream","text":"TRAIN DATASET\nPositve, negative , neutral count = \n8029 8051 33920\n-------------------------------------\nTEST DATASSET\nPositve, negative , neutral count = \n792 769 3439\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Setup experiments "},{"metadata":{"trusted":true},"cell_type":"code","source":"ngrams = (1, 2, 3)\nresults = []\n\n\nclassifiers = [SVC(), LogisticRegression(),\n               RandomForestClassifier(max_depth=20, n_estimators=10, max_features=3),\n               KNeighborsClassifier(5)\n               ]\nfor g in ngrams:\n    dataset = load2(\"../input/kaust-arabic-nlp/full_labeled_data.csv\")\n    for alg in classifiers:\n        alg_name = alg.__class__.__name__\n        r = do_sa(g, alg, alg_name, dataset)\n        results.append(r)\n        ","execution_count":9,"outputs":[{"output_type":"stream","text":"data sample\n------------------------------------\nparameters\nn grams: 1\nclassifier: LinearSVC\n------------------------------------\n              precision    recall  f1-score   support\n\n         pos       0.55      0.48      0.51       812\n         neg       0.53      0.43      0.47       809\n        neut       0.80      0.86      0.82      3379\n\n    accuracy                           0.73      5000\n   macro avg       0.62      0.59      0.60      5000\nweighted avg       0.71      0.73      0.72      5000\n\n[[ 393   66  353]\n [  76  345  388]\n [ 249  238 2892]]\n# of features: 112635\nsample of features: ['بالعناية', 'يكشف', 'التعاقدات', 'ومسيان', 'إحزاني', 'أتركك', 'النحاسية', 'دكاتره', 'مديني', 'الملهى', 'أحل', '63', 'بتجميع', 'julb9xyymg', 'فيلق', 'اطلعي', 'فهدنا', 'چوى', 'وكفيل', 'يعقل', '0vjtfmce3o', 'حرمته', 'استخيرو', 'البريد', 'ومشاءاللهه', 'لمختلف', 'الرشيدة', 'يأمر', 'متاخرين', 'والاطفال', 'جاهك', 'نيتكم', 'الحقـد', 'بريلش', 'حاجة', 'سلطان_الغنام', 'دنيئه', 'حيقابلك', 'الإنتظار', 'يستقر']\nparameters\nn grams: 1\nclassifier: SVC\n------------------------------------\n              precision    recall  f1-score   support\n\n         pos       0.76      0.32      0.45       812\n         neg       0.75      0.21      0.32       809\n        neut       0.74      0.97      0.84      3379\n\n    accuracy                           0.74      5000\n   macro avg       0.75      0.50      0.54      5000\nweighted avg       0.75      0.74      0.69      5000\n\n[[ 263   16  533]\n [  22  167  620]\n [  61   39 3279]]\n# of features: 112635\nsample of features: ['وغفل', 'أميال', 'حضار', 'فاروق', 'nوينامون', 'وديه_تح', 'للفطرة', 'مستهتر', 'ينفضك', 'صفح', 'قرأ', 'روحهم', 'عالمعاشات', 'للتانى', 'محسوبه', 'الهيشه', 'nالكبير', 'اخبرك', 'القديس', 'مودم', 'فصار', 'البدو', 'وجبة', 'جرما', 'nجهد', 'تزودوني', 'قاعدته', 'تايلاند', '5qo5qqm4un', 'الجابر', 'تقف', 'لاحتضان', 'تزاور', 'chassis', 'مستفادة', 'الصالحة', 'وتوصلني', 'الخيل', 'يرغبون', 'فمنهم']\nparameters\nn grams: 1\nclassifier: LogisticRegression\n------------------------------------\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","name":"stderr"},{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n         pos       0.61      0.44      0.52       812\n         neg       0.59      0.40      0.48       809\n        neut       0.79      0.90      0.84      3379\n\n    accuracy                           0.74      5000\n   macro avg       0.66      0.58      0.61      5000\nweighted avg       0.73      0.74      0.73      5000\n\n[[ 361   47  404]\n [  57  327  425]\n [ 170  177 3032]]\n# of features: 112635\nsample of features: ['ب90000الف', 'gcfrphmlww', 'قيصري', 'الوتر_جنة_القلوب', 'نعيها', 'لبتس', 'واجعلهم', 'alsaifgallery', 'xopjmzjqj2', 'yarb44360835', 'توجل', 'لتغطية', 'مضحك', '٢٠٣٠', 'قبيلته', 'وتميل', 'أبلغت', 'أعر', 'nالحين', 'يستاهل', 'n2402347971', 'الفاتور', 'لمباشرة', 'الغموض', 'تسمعيها', 'جامعية', 'الانصاف', 'shaggiekay', 'يجزيكم', '0544779488', 'نوته', 'تاريخ٢', 'برياضة', '٧٧', 'والمحل', 'وطارت', 'استعملت', 'ارضيتي', 'سأخبركم', 'اتفضلي']\nparameters\nn grams: 1\nclassifier: RandomForestClassifier\n------------------------------------\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","name":"stderr"},{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n         pos       0.00      0.00      0.00       812\n         neg       0.00      0.00      0.00       809\n        neut       0.68      1.00      0.81      3379\n\n    accuracy                           0.68      5000\n   macro avg       0.23      0.33      0.27      5000\nweighted avg       0.46      0.68      0.55      5000\n\n[[   0    0  812]\n [   0    0  809]\n [   0    0 3379]]\n# of features: 112635\nsample of features: ['الشد', 'زهران', 'الإستفاده', 'دمت', 'يخبر', 'الافتتاح', 'الوو', 'alshammry_saja', 'شاي', 'تنتحر', 'اللافت', 'y6nuiqxfjm', 'كفيلة', 'اقولهم', 'مستغانمي', 'احوالي', 'algadiarawi', 'ويخليه', 'coffeeraeq', 'tiribark_', 'لجوازي', 'غسلت', 'إنطفأ', 'ban7erhfc', 'وزادت', 'لمواجهه', 'حاسوبية', 'اكوون', 'أضخم', 'قليلا', 'يأسك', 'شقو', 'أكسب', 'تجر', 'بارجع', 'طفولته', 'لدخول', 'osuzdtplkm', 'بمكتب', 'أتجول']\nparameters\nn grams: 1\nclassifier: KNeighborsClassifier\n------------------------------------\n              precision    recall  f1-score   support\n\n         pos       0.38      0.17      0.23       812\n         neg       0.52      0.06      0.11       809\n        neut       0.70      0.94      0.80      3379\n\n    accuracy                           0.67      5000\n   macro avg       0.53      0.39      0.38      5000\nweighted avg       0.62      0.67      0.60      5000\n\n[[ 135   12  665]\n [  52   49  708]\n [ 166   34 3179]]\n# of features: 112635\nsample of features: ['المجردة', 'سجينا', 'آفاق_مالية_واعدة', 'abbassi2020', 'سويتها', 'تعوم', 'أخ', 'لانه', 'بريميوم', 'وأتقاوى', 'إستقرار', 'اساطير', 'الطبقات', 'رايعه', 'غذائية', 'العاطفه', 'تتدعي', 'صباحك_ومطرحك_عالراديو9090', 'برأسي', 'إعلامية', 'الامن', 'بعتت', 'ونعين', 'جينات', 'عنه', 'a28wndbhq3', 'حتملى', 'كنافذة', 'ونمت', 'اخونك', 'زائر', 'الرخصة', 'صادمتك', 'التنبي', 'ذكروني', 'شرايينك', 'اغلاق_المحلات_وقت_الصلاه11', 'yj6cey4qda', 'المح', 'asr3follw1']\ndata sample\n------------------------------------\nparameters\nn grams: 2\nclassifier: LinearSVC\n------------------------------------\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/svm/_base.py:977: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  \"the number of iterations.\", ConvergenceWarning)\n","name":"stderr"},{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n         pos       0.56      0.48      0.51       796\n         neg       0.52      0.42      0.46       830\n        neut       0.79      0.85      0.82      3374\n\n    accuracy                           0.72      5000\n   macro avg       0.62      0.58      0.60      5000\nweighted avg       0.71      0.72      0.71      5000\n\n[[ 382   72  342]\n [  56  348  426]\n [ 250  248 2876]]\n# of features: 112411\nsample of features: ['a45xq3oo8v', 'اليوقا', 'mawhiba_care', 'xh5fzs8ie4', 'يبصره', 'abdulaziztf', 'التأثر', 'بلهيب', 'الطبيه', 'درهت', '893', 'اعيت', 'أهتمامگ', 'psycfact', 'بـعضنا', 'وعزل', 'جيكم', 'وحفظا', 'أدير', 'كشف', 'عمله', 'برعايه', 'نمبسط', 'يستانس', 'اللوجو', 'omaryou91129630', 'لث', 'احبـاب', 'rhlraetglc', 'e_balady', 'والتقاليد', 'نكتة', 'يهوي', 'بسلبياتك', 'فسوف', 'تـمـنـيت', 'ftj3fh1aph', 'المتفتح', 'الروم', 'رفح']\nparameters\nn grams: 2\nclassifier: SVC\n------------------------------------\n              precision    recall  f1-score   support\n\n         pos       0.68      0.31      0.43       796\n         neg       0.75      0.20      0.31       830\n        neut       0.73      0.96      0.83      3374\n\n    accuracy                           0.73      5000\n   macro avg       0.72      0.49      0.52      5000\nweighted avg       0.73      0.73      0.68      5000\n\n[[ 247   16  533]\n [  26  165  639]\n [  91   38 3245]]\n# of features: 112411\nsample of features: ['همجي', 'pl3', 'الأدلاء', '90_cutte', 'طرية', 'أعانه', 'هجومية', 'ومسافرين', 'والثواب', 'فيرنانديز', 'الإلكترونية', 'طحـــناهم', 'ردا', 'تلاقي', 'حشرك', 'nأحبها', 'امسكوهم', 'استإناف', 'وحبل', 'fadak', 'الجبير', 'المشطوبة', 'mahmoodmath', 'بلاكم', 'تلاتين', 'شتم', 'يامتحدث', '193827952', 'محرمه', 'nمتى', 'بأسمك', 'يلطش', 'ضعفونه', 'f354t074c9kvodv', 'تعاتب', 'بستفرغ', 'بضغط', 'أسلوبي', 'nقصف', 'الإثم']\nparameters\nn grams: 2\nclassifier: LogisticRegression\n------------------------------------\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","name":"stderr"},{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n         pos       0.59      0.44      0.50       796\n         neg       0.59      0.39      0.47       830\n        neut       0.78      0.89      0.83      3374\n\n    accuracy                           0.74      5000\n   macro avg       0.66      0.57      0.60      5000\nweighted avg       0.72      0.74      0.72      5000\n\n[[ 348   54  394]\n [  48  326  456]\n [ 189  169 3016]]\n# of features: 112411\nsample of features: ['مخالفاتي', 'حقوقك', 'والمواطنين', 'wie0jqouex', 'nامر', 'أصدر', 'قراد', 'المتواصل', 'بنرفع', 'المشتكى', 'escapesaudi', 'احتري', 'لرسولنا', 'ماارتحت', 'نشتغل', 'المتبدل', 'واخد', 'shame', 'والسيطرة', 'ينفذ', 'صناعة_الترفيه', 'nهههههه', 'lo5h2jafkp', 'استشهاد', 'eztos9mfzl', 'توصف', 'جميييييله', 'العارض', 'ومساهماتهم', 'جعجعه', 'az__2133', 'قطـر', 'واستفيد', 'بزلة', 'خذاله', 'والإحتجاز', 'وتقب', 'هالصورة', '0019104', 'jbreel_faqyh90']\nparameters\nn grams: 2\nclassifier: RandomForestClassifier\n------------------------------------\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","name":"stderr"},{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n         pos       0.00      0.00      0.00       796\n         neg       0.00      0.00      0.00       830\n        neut       0.67      1.00      0.81      3374\n\n    accuracy                           0.67      5000\n   macro avg       0.22      0.33      0.27      5000\nweighted avg       0.46      0.67      0.54      5000\n\n[[   0    0  796]\n [   0    0  830]\n [   0    0 3374]]\n# of features: 112411\nsample of features: ['باسقاط', 'مابقدر', 'وماتغير', 'واخواتك', 'سكنها', 'معالفها', 'بالتوصيل', 'وإنتهى', 'التعرض', 'omarmuktar15', 'والطاعة', 'النهاءي', 'الكرتوني', 'تتصرف', 'nمابي', 'تجود', 'تطورنا', 'حجم', 'مسامحة', 'مآفي', 'رابطة_المتكممين', 'زيف', '٢٥٠٠', 'ستغرم', 'أسهب', 'بشفائه', 'rowadalkhaleej', 'بإعلان', 'ندري', 'o6imkl0bub', 'بالتوظيف', 'هتتركب', 'بدوخخخه', 'imamuelearn', 'انجلوس', 'مودريتش', 'متحمسة', 'ملوي', 'خسرناها', 'وجا']\nparameters\nn grams: 2\nclassifier: KNeighborsClassifier\n------------------------------------\n              precision    recall  f1-score   support\n\n         pos       0.40      0.18      0.25       796\n         neg       0.52      0.07      0.12       830\n        neut       0.70      0.94      0.80      3374\n\n    accuracy                           0.67      5000\n   macro avg       0.54      0.40      0.39      5000\nweighted avg       0.62      0.67      0.60      5000\n\n[[ 145   14  637]\n [  44   59  727]\n [ 175   41 3158]]\n# of features: 112411\nsample of features: ['اغلا', 'وغيابهم', 'الفنيون', 'متماشية', 'الدخان_الجديد_مغشوش63', 'ob80qzikoi', 'موووووبايلي', 'nارحو', 'ونهبها', 'بالجبيل', 'أبخص', 'المرابع', 'وخط', 'وذالك', 'يقابلك', 'سائلة', 'شفناها', 'الجفى', 'جرافة', 'للأستمارة', 'فضلا', 'فريكا', 'ترده', 'نحافظ', 'ومر', '9_aishaikh', 'sara3bdu', 'ahlawimlki1234', 'حيثةاسم', 'وأروح', 'وبيالله', 'althqilabdullah', 'لإلغاء', 'ومحلات', 'nستجد', 'منتصفها', 'ينطف', 'nعلامة', 'السليم', 'زي']\ndata sample\n------------------------------------\nparameters\nn grams: 3\nclassifier: LinearSVC\n------------------------------------\n              precision    recall  f1-score   support\n\n         pos       0.55      0.49      0.52       813\n         neg       0.54      0.42      0.47       822\n        neut       0.79      0.85      0.82      3365\n\n    accuracy                           0.72      5000\n   macro avg       0.62      0.59      0.60      5000\nweighted avg       0.71      0.72      0.71      5000\n\n[[ 396   63  354]\n [  64  349  409]\n [ 263  239 2863]]\n# of features: 112511\nsample of features: ['هواياتي', 'وشاي', 'تردعهم', 'شاهة', 'nوايش', 'نفهم', 'لكمبسبب', 'أيديينا', 'industrie', 'تو', 'malakbaghdad1', 'faght13', 'انامشكلتي', 'اهدنا', 'الmood', 'وسأقول', 'هوى', 'امك', 'والتحضير', 'للذهاب', 'متصير', 'احتجتني', 'تنظيمه', 'ومشتقه', 'الخدمه', 'تال', 'الدخله', 'انزله', 'وفقدتك', 'الأهمية', 'المخلوقات', 'ليحكم', 'الخرج', 'مهبط', 'فانزه', 'احسنت', 'krakn112', 'doniaellithy', 'انسداد', 'تنرفض']\nparameters\nn grams: 3\nclassifier: SVC\n------------------------------------\n              precision    recall  f1-score   support\n\n         pos       0.76      0.33      0.46       813\n         neg       0.76      0.20      0.32       822\n        neut       0.73      0.97      0.84      3365\n\n    accuracy                           0.74      5000\n   macro avg       0.75      0.50      0.54      5000\nweighted avg       0.74      0.74      0.69      5000\n\n[[ 266   11  536]\n [  18  164  640]\n [  67   42 3256]]\n# of features: 112511\nsample of features: ['poetryyt1', 'مرورك', 'تكفل', 'تلحقنا', 'eyywkkvlad', 'brahimie95', 'نومتك', 'والغضب', 'متزوجات', 'والكلام', 'استدعاء', 'المدنين', 'النماص', 'تتابع', 'يبدلني', 'تصاريح', 'يتوجة', 'وسترت', 'nاشتراك', 'ماأتضايق', 'كمارا_اتحادي', 'الرجعي', 'رواسي_نجد', 'والحان', 'وريح', 'انسحاب', 'لسلامة', 'بهضم', 'محتاجينكم', 'وابطاء', 'باذنجان', 'الغالـي', 'nنشوى', 'يعينك', 'حقتتهم', 'بيتناسب', 'بالعرض', 'تكسرني', 'الحاضرين', 'مايعتبرون']\nparameters\nn grams: 3\nclassifier: LogisticRegression\n------------------------------------\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n","name":"stderr"},{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n         pos       0.61      0.46      0.52       813\n         neg       0.60      0.40      0.48       822\n        neut       0.78      0.89      0.83      3365\n\n    accuracy                           0.74      5000\n   macro avg       0.67      0.58      0.61      5000\nweighted avg       0.72      0.74      0.73      5000\n\n[[ 371   42  400]\n [  54  328  440]\n [ 179  176 3010]]\n# of features: 112511\nsample of features: ['البطولية', 'القرمزية', 'الثور', 'إبصار', 'أتهم', 'تلخبطها', 'وذكريات', 'دمنه', '4q', 'والاغرب', 'انتحالف', 'بالسقف', 'فاتورة', 'حام', 'بموضوعية', 'جابه', 'بالسنة', 'ألهمني', 'بحياة', 'عقولهم', 'اعطاها', 'أرضاني', 'تعافت', 'w88jheeiac', 'vs3', 'حدوثها', 'املنا', 'البطانيات', 'سنتصل', 'وفرنسا', 'nأريد', 'الشخصية', 'للزلام', 'pc3', 'مـاتت', 'تهزر', 'الشآن', 'مستحقاته', 'تجمعنا', 'البلطان']\nparameters\nn grams: 3\nclassifier: RandomForestClassifier\n------------------------------------\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","name":"stderr"},{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n         pos       0.00      0.00      0.00       813\n         neg       0.00      0.00      0.00       822\n        neut       0.67      1.00      0.80      3365\n\n    accuracy                           0.67      5000\n   macro avg       0.22      0.33      0.27      5000\nweighted avg       0.45      0.67      0.54      5000\n\n[[   0    0  813]\n [   0    0  822]\n [   0    0 3365]]\n# of features: 112511\nsample of features: ['إببرييل', 'يصبرها', 'مصارعة', 'ناااااس', 'هيتنسي', 'حسو', 'الندوة', 'الاجنبية', 'لخوياه', 'غريميو', 'القرار', 'اوده', 'باصصلي', 'أشوا', 'الموظف2460519040', 'والبدر', 'للدكه', 'مرتضي', 'مغلفة', 'nوكيفكم', 'nاسبوعين', 'وأقبلك', 'اجلالا', 'الخدم', 'بحوائج', 'i_2il', 'القوات', 'ازهرها', 'اصدار', 'مسموعة', 'بالحوار', '1jcryymga9', 'ميبقاش', 'تتعودين', 'خدو', 'واقولك', 'يدويا', 'aeyfq', 'غدت', 'بختهم']\nparameters\nn grams: 3\nclassifier: KNeighborsClassifier\n------------------------------------\n              precision    recall  f1-score   support\n\n         pos       0.38      0.17      0.24       813\n         neg       0.60      0.08      0.13       822\n        neut       0.70      0.94      0.80      3365\n\n    accuracy                           0.67      5000\n   macro avg       0.56      0.40      0.39      5000\nweighted avg       0.63      0.67      0.60      5000\n\n[[ 142    7  664]\n [  59   62  701]\n [ 176   34 3155]]\n# of features: 112511\nsample of features: ['ياكحيلان', 'والخلايق', 'التخزينة', 'عشتها', 'والعتب', 'صامتة', 'باجمل', 'nزير', 'البسام', 'تؤرق', 'تجدونها', 'اكاد', 'للرعايه', 'ومانقدر', 'نشبت', 'لزيادة', 'للشمس', 'ربحت', 'وخربت', 'تجاري', 'فصيلة', 'وبيلا', '٣٠م', 'تكتسبونه', 'أكلوا', 'وشواطئها', 'بعمله', 'cam', 'اللعين', 'لاتسمحي', 'يستاهلوا', 'bxma5p8dtk', 'تركبوا', 'وذكرت', 'بصرف', 'حنونه', 'تحتبس', 'عليڪم', 'تشبيح', 'حقكم']\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":" #  Results Summary"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('{0:25}{1:10}{2:10}{3:15}{4:10}{5:10}{6:10}{7:10}{8:10}'.format('algorithm', 'ngram', 'accuracy', 'precision', 'p_rec','n_rec', 'u_rec', 'avg_rec','f1_pn'))\nprint('------------------------------------------------------------------------------------------------------------')\nfor r in results:\n    print('{0:25}{1:10}{2:10.3f}{3:10.3f}{4:10.3f}{5:10.3f}{6:10.3f}{7:10.3f}{8:10.3f}'.format(r[0], r[1], r[2], r[3], r[4][0], r[4][1], r[4][2], sum(r[4])/3, r[5]))","execution_count":18,"outputs":[{"output_type":"stream","text":"algorithm                ngram     accuracy  precision      p_rec     n_rec     u_rec     avg_rec   f1_pn     \n------------------------------------------------------------------------------------------------\nLinearSVC                         1     0.726     0.713     0.484     0.426     0.856     0.589     0.493\nSVC                               1     0.742     0.745     0.324     0.206     0.970     0.500     0.389\nLogisticRegression                1     0.744     0.726     0.445     0.404     0.897     0.582     0.498\nRandomForestClassifier            1     0.676     0.457     0.000     0.000     1.000     0.333     0.000\nKNeighborsClassifier              1     0.673     0.618     0.166     0.061     0.941     0.389     0.170\nLinearSVC                         2     0.721     0.707     0.480     0.419     0.852     0.584     0.490\nSVC                               2     0.731     0.729     0.310     0.199     0.962     0.490     0.370\nLogisticRegression                2     0.738     0.720     0.437     0.393     0.894     0.575     0.488\nRandomForestClassifier            2     0.675     0.455     0.000     0.000     1.000     0.333     0.000\nKNeighborsClassifier              2     0.672     0.621     0.182     0.071     0.936     0.396     0.188\nLinearSVC                         3     0.722     0.709     0.487     0.425     0.851     0.587     0.495\nSVC                               3     0.737     0.742     0.327     0.200     0.968     0.498     0.386\nLogisticRegression                3     0.742     0.725     0.456     0.399     0.895     0.583     0.502\nRandomForestClassifier            3     0.673     0.453     0.000     0.000     1.000     0.333     0.000\nKNeighborsClassifier              3     0.672     0.630     0.175     0.075     0.938     0.396     0.186\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}